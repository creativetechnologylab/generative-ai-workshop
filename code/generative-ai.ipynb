{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef47f24",
   "metadata": {},
   "source": [
    "# Generative AI with Python (with some Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e271a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bcbee",
   "metadata": {},
   "source": [
    "## Text to Image with StableDiffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e249b",
   "metadata": {},
   "source": [
    "## Large Language Models (LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754f3b4",
   "metadata": {},
   "source": [
    "### What are Large Language Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a17cd",
   "metadata": {},
   "source": [
    "Large Language Models \n",
    "\n",
    "\"auto-correct on steroids\"\n",
    "\n",
    "[A short introduction to LLMs](https://www.youtube.com/watch?v=LPZh9BOjkQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01640ab8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Ollama & Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf3a8f",
   "metadata": {},
   "source": [
    "**Ollama** is a tool that allows us to run LLMs locally. It can be downloaded and used entirely for _free_.\n",
    "\n",
    "But what does it mean to run something _locally_? That means you're running it _solely_ on your own machine, rather than sending information back and forth with an online service.\n",
    "\n",
    "This has some key advantages:\n",
    "- cost\n",
    "- privacy\n",
    "- doesn't depend on stable/fast internet access\n",
    "- peformance doesn't depend upon how many people are using online services at a given time\n",
    "\n",
    "To test this, we can see the output from inputting `ollama` in the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b72f1",
   "metadata": {},
   "source": [
    "Python lets us do this too by using the `subprocess` library. So that's one option..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0af523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from command line:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  ollama [flags]\n",
      "  ollama [command]\n",
      "\n",
      "Available Commands:\n",
      "  serve       Start ollama\n",
      "  create      Create a model from a Modelfile\n",
      "  show        Show information for a model\n",
      "  run         Run a model\n",
      "  stop        Stop a running model\n",
      "  pull        Pull a model from a registry\n",
      "  push        Push a model to a registry\n",
      "  list        List models\n",
      "  ps          List running models\n",
      "  cp          Copy a model\n",
      "  rm          Remove a model\n",
      "  help        Help about any command\n",
      "\n",
      "Flags:\n",
      "  -h, --help      help for ollama\n",
      "  -v, --version   Show version information\n",
      "\n",
      "Use \"ollama [command] --help\" for more information about a command.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the `echo` command and capture output\n",
    "result = subprocess.run([\"ollama\"], text=True)\n",
    "\n",
    "print(\"Output from command line:\")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f3473",
   "metadata": {},
   "source": [
    "This is simply telling us how we can use Ollama through the command line. However, Ollama has its own Python library too. We can then use this to incorporate text generated by LLMs into Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2dbfc",
   "metadata": {},
   "source": [
    "To start with, I'm going to create a _variable_ for storing the name of the model I wish to use. This is going to be a _parameter_ that we give repeatedly to the ollama python library, so it makes sense to write it down once and avoid repeating ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6fd9a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dophin-phi is 2.7b\n",
    "DOLPHIN_PHI = \"dolphin-phi\"\n",
    "# this particular deepseek model is 7b\n",
    "DEEPSEEK = \"deepseek-r1:7b\"\n",
    "# glm4 9b version\n",
    "GLM4 = \"glm4:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a1111",
   "metadata": {},
   "source": [
    "A convention when programming in Python is to write constants -- variables that are set once and never changes -- in all-caps. This doesn't affect how your code runs, but it can be nice for making things more ordered. I feel it tells me this bit of information is \"important\" in some way, while using less mental effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf6360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "response = chat(model=DOLPHIN_PHI, messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'What is the capital of France?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87600bd5",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89a0c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to the phenomenon known as Rayleigh scattering. When sunlight enters the Earth's atmosphere, it interacts with molecules in the air such as nitrogen and oxygen. These molecules are much smaller than the wavelength of visible light (around 400-700 nm), which is why they can scatter the shorter-wavelength colors more effectively, like blue.\n",
      "\n",
      "However, the sky isn't really blue at all. The light from the sun gets scattered in all directions by these molecules in the atmosphere and our eyes perceive this as a \"blue\" color. When the sunlight passes through Earth's atmosphere, it is broken up into its different colors due to Rayleigh scattering. Blue light has a shorter wavelength, so it is scattered more than the other colors of visible light, which are longer in wavelength. This makes the sky appear blue from our perspective on the ground.\n",
      "\n",
      "The deeper you look into the sky, the further away the sun is and the longer the path sunlight travels, causing more scattering of shorter wavelengths of light to be absorbed by the atmosphere. At sunset or sunrise when the sun is low on the horizon, the light has to pass through a larger portion of Earth's atmosphere, which scatters even more blue light and causes the sky to turn various shades of red and orange."
     ]
    }
   ],
   "source": [
    "stream = chat(\n",
    "    model=DOLPHIN_PHI,\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8907377",
   "metadata": {},
   "source": [
    "### Vision Language Models (VLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468c26c",
   "metadata": {},
   "source": [
    "### Small Language Models\n",
    "\n",
    "Language Models come in very small sizes too. Some examples include `smollm` and `tinyllama`. While these models are more prone to hallucination, and have more limited \"intelligence,\" they can run quite fast even on less powerful hardware such as Raspberry Pis and computers with older GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e60b6b",
   "metadata": {},
   "source": [
    "### Hallucination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91aee88",
   "metadata": {},
   "source": [
    "![](../pictures/how-to-cook-your-dragon.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07d135c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Dragon Meat by Dragon\" by Stephen Marche: This is an excellent book for beginners who want to learn about the culinary possibilities of dragon meat. It offers a variety of recipes that cater to different taste preferences and skill levels, with detailed instructions and photographs to guide you along the way. \n",
      "\n",
      "2. \"The Dragon’s Feast\" by Chris Alder: This cookbook is particularly interesting as it uses dragon meat in an innovative and creative manner. The book features a range of dishes that are both delicious and visually stunning, making it an ideal choice for those looking to experiment with new flavors and techniques. \n",
      "\n",
      "3. \"Dragon Cuisine: Recipes from the Dragon Kingdom\" by Dragon-Chef James Lee: This book is specifically tailored to dragon meat and offers a variety of recipes that showcase the unique flavor and texture of this exotic ingredient. The recipes are easy to follow and include tips for preparing and cooking dragon meat in different ways. \n",
      "\n",
      "4. \"Dragon Tales: Celebrating Dragon Cuisine\" by Dragon-Chef Sarah Chen: This book is a collection of personal stories and recipes from various chefs, including some of the best in the world. It provides a unique perspective on dragon cuisine and offers readers an insight into the diverse range of flavors and dishes that can be created using dragon meat. \n",
      "\n",
      "5. \"Dragon Chef’s Cookbook\" by Dragon-Chef Mark Johnson: This is a comprehensive guide to dragon cuisine, with recipes for everything from simple appetizers to complex main courses. The book also includes information on how to prepare and cook dragon meat safely, making it an ideal resource for those who are new to working with this unique ingredient. \n",
      "\n",
      "6. \"Dragon Meat Cooking\" by Dragon-Chef Michael Wong: This is a popular cookbook that offers a range of recipes for cooking dragon meat in different ways. The book is well-organized and easy to follow, making it an ideal resource for both beginners and experienced cooks. \n",
      "\n",
      "7. \"Dragon Tales Cookbook\" by Dragon-Chef Rachel Kim: This book is specifically focused on using dragon meat in various dishes from around the world. It includes recipes from different cuisines, as well as a range of preparation methods and techniques that are perfect for working with this exotic ingredient. \n",
      "\n",
      "8. \"The Dragon’s Bounty\" by Chef John Smith: This cookbook is an excellent resource for those who want to learn how to work with dragon meat in more complex dishes. The book includes a range of recipes, many of which feature dragon meat as the star ingredient, along with detailed instructions on how to prepare and cook the meat. \n",
      "\n",
      "9. \"Dragon Meat 101\" by Chef Lisa Chen: This is a beginner-friendly guide to working with dragon meat in the kitchen. It offers tips and tricks for preparing and cooking this exotic ingredient, as well as a range of simple recipes that are perfect for those who are just starting out. \n",
      "\n",
      "10. \"The Ultimate Guide to Cooking with Dragon Meat\" by Chef Peter Lee: This is a comprehensive guide to working with dragon meat in the kitchen. The book offers tips and techniques for preparing and cooking this unique ingredient, as well as a range of recipes that showcase the versatility of dragon meat.\n"
     ]
    }
   ],
   "source": [
    "response = chat(model=DOLPHIN_PHI, messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'What are some good cookbooks on how to use dragon meat?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b51356",
   "metadata": {},
   "source": [
    "### Finding the \"Best\" Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c442ec9",
   "metadata": {},
   "source": [
    "trade-offs with sensible output and size/speed  \n",
    "trial and error experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6a628",
   "metadata": {},
   "source": [
    "We can create a quick comparison test by asking various models to generate text based on the same prompt, and see which output we like the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8c92d",
   "metadata": {},
   "source": [
    "Firstly, we can take all the models that are on the system right now, and place them in a Python list. This will make things easier in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df182f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DOLPHIN_PHI, DEEPSEEK, GLM4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a6014",
   "metadata": {},
   "source": [
    "Now, we can create a _function_ for sending the same prompt to different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b774de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limerick_creator(model: str):\n",
    "    response = chat(model=model, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Write a limerick about the nature of time.',\n",
    "    },\n",
    "    ])\n",
    "    \n",
    "    print(\"Model:\", model)\n",
    "    print(response['message']['content'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf4f7a",
   "metadata": {},
   "source": [
    "Now we can _call_ this function with our different models, and see how the output varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28689e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: dolphin-phi\n",
      "There once was a concept called time,\n",
      "Its ticking clock could not be chime,\n",
      "It flowed like a river swift,\n",
      "Past and future with a shift,\n",
      "Leaving moments in its wake so bright.\n",
      "\n",
      "\n",
      "Model: deepseek-r1:7b\n",
      "<think>\n",
      "Alright, so I need to write a limerick about the nature of time. Hmm, okay. First off, what is a limerick? From what I remember, it's a five-line poem with an AABBA rhyme scheme. It usually has a playful or rhythmic feel to it and often tells a short story or conveys a light-hearted message.\n",
      "\n",
      "Now, the topic here is the nature of time. Time can be tricky because it's something we all experience every day but isn't tangible—it's more of an abstract concept. I guess I could approach this in different ways: maybe talking about how time moves us forward without pause, or perhaps the idea that time doesn't care who waits for it.\n",
      "\n",
      "I should think about imagery related to time—maybe clocks, the ticking sound, seasons passing, aging, or moments rushing by too quickly. Using some rhyme and rhythm here will be key. Let me try to come up with a structure: first line introduces the subject of time; second and third lines delve into its nature or behavior; fourth line might offer a perspective on how it's perceived; fifth line is usually a punchline or a conclusion.\n",
      "\n",
      "Let me see... Maybe start with something like \"There once was a time, oh what fun,\" but wait, that doesn't fit the limerick structure. Alternatively, I could try to think of a metaphor involving movement since time often feels like it's moving forward.\n",
      "\n",
      "Wait, another thought: perhaps using the image of a river running or a child skipping stones over water because time glides by quickly. That could tie into the idea of time passing without stopping and how we don't notice it when it does go by.\n",
      "\n",
      "Putting that together:\n",
      "\n",
      "\"There once was a river so clear,\"  \n",
      "\"Where time's waves seemed to skip.\"  \n",
      "But then I need to fit in something about its nature, maybe how time doesn't wait for anyone. Let me try another angle: comparing time to something that's always moving without rest.\n",
      "\n",
      "Maybe something like \"Time has no bounds, it goes on and on,\" but make it rhyme. Hmm, perhaps using \"snaps through the fingers of man\" from Alice in Wonderland as a metaphor? Not sure if that's the best fit here.\n",
      "\n",
      "Wait, let me try to think of some lines:\n",
      "\n",
      "\"The clock ticks softly, soft as a bell,\"  \n",
      "\"But time is faster, quicker than we'll see.\"  \n",
      "But then I need more lines. Maybe add something about how it doesn't stop for anyone and how we often resist its flow.\n",
      "\n",
      "Wait, maybe the first line could be \"Time is a thief\" or \"Time moves swiftly.\" Let me try that:\n",
      "\n",
      "\"There's a thief in the night, quick as can be,\"  \n",
      "\"Who steals away moments when we're not asleep.\"  \n",
      "That has rhyme and rhythm. Now for the next lines: perhaps how time doesn't wait for anyone.\n",
      "\n",
      "\"But he takes what he wants, with little pause,\"  \n",
      "\"He leaves our days before our years can save.\"  \n",
      "Now I'm at four lines. The fifth line should wrap it up or add a twist. Maybe something like \"So hurry up and be ready\" to catch up? But that's more of a command than a statement about time.\n",
      "\n",
      "Alternatively, maybe the last couplet could express a perspective on life in relation to time:\n",
      "\n",
      "\"So watch the moments as they pass by,\"  \n",
      "\"Time's a trickster, always changes my way.\"  \n",
      "Hmm, not sure if that's strong enough. Let me try again with different wording for the last two lines.\n",
      "\n",
      "Perhaps something like \"Time moves on without pause, It takes what it will, and leaves its trace.\"\n",
      "\n",
      "Wait, putting it all together:\n",
      "\n",
      "\"There was once a thief in the night,\"  \n",
      "\"Who steals away moments when we rest.\"  \n",
      "\"He takes what he wants, with little delay,\"  \n",
      "\"And leaves our days before our years grow old.\"  \n",
      "\"So watch the moments as they pass by,\"  \n",
      "\"Time's a trickster, always changes my way.\"\n",
      "\n",
      "Hmm, that works. It follows the AABBA rhyme scheme and touches on time moving quickly without pause, taking what it wants, leaving in its wake, making us realize how fast our days fly.\n",
      "\n",
      "I think this captures the essence of the limerick structure while conveying something about time's nature—its swift movement and impact on our lives.\n",
      "</think>\n",
      "\n",
      "There once was a thief in the night,  \n",
      "Who steals away moments when we rest.  \n",
      "He takes what he wants, with little delay,  \n",
      "And leaves our days before our years grow old.  \n",
      "\n",
      "So watch the moments as they pass by,  \n",
      "Time's a trickster, always changes my way.\n",
      "\n",
      "\n",
      "Model: glm4:latest\n",
      "There once was time so swift and fleet,  \n",
      "With moments that could seem complete;  \n",
      "But then it's past, as if a dream,  \n",
      "And each second dances in a beam —  \n",
      "Nature’s clock keeps on a tick.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    limerick_creator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053a57f",
   "metadata": {},
   "source": [
    "## Other ML Tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
