{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef47f24",
   "metadata": {},
   "source": [
    "# Generative AI with Python (with some Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e271a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e249b",
   "metadata": {},
   "source": [
    "## Large Language Models (LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01640ab8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Ollama & Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf3a8f",
   "metadata": {},
   "source": [
    "**Ollama** is a tool that allows us to run LLMs locally. It can be downloaded and used entirely for _free_.\n",
    "\n",
    "But what does it mean to run something _locally_? That means you're running it _entirely_ on your own machine, rather than sending information back and forth with an online service.\n",
    "\n",
    "This has some key advantages:\n",
    "- cost\n",
    "- privacy\n",
    "- doesn't depend on stable/fast internet access\n",
    "- peformance doesn't depend upon how many people are using online services at a given time\n",
    "\n",
    "To test this, we can see the output from inputting `ollama` in the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b72f1",
   "metadata": {},
   "source": [
    "Python lets us do this too by using the `subprocess` library. So that's one option..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0af523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from command line:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  ollama [flags]\n",
      "  ollama [command]\n",
      "\n",
      "Available Commands:\n",
      "  serve       Start ollama\n",
      "  create      Create a model from a Modelfile\n",
      "  show        Show information for a model\n",
      "  run         Run a model\n",
      "  stop        Stop a running model\n",
      "  pull        Pull a model from a registry\n",
      "  push        Push a model to a registry\n",
      "  list        List models\n",
      "  ps          List running models\n",
      "  cp          Copy a model\n",
      "  rm          Remove a model\n",
      "  help        Help about any command\n",
      "\n",
      "Flags:\n",
      "  -h, --help      help for ollama\n",
      "  -v, --version   Show version information\n",
      "\n",
      "Use \"ollama [command] --help\" for more information about a command.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the `echo` command and capture output\n",
    "result = subprocess.run([\"ollama\"], text=True)\n",
    "\n",
    "print(\"Output from command line:\")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f3473",
   "metadata": {},
   "source": [
    "This is simply telling us how we can use Ollama through the command line. However, Ollama has its own Python library too. We can then use this to incorporate text generated by LLMs into Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2dbfc",
   "metadata": {},
   "source": [
    "To start with, I'm going to create a _variable_ for storing the name of the model I wish to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fd9a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"dolphin-phi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a1111",
   "metadata": {},
   "source": [
    "A convention when programming in Python is to write constants -- variables that are set once and never changes -- in all-caps. This doesn't affect how your code runs, but it can be nice for making things more ordered. I feel it tells me this bit of information is \"important\" in some way, while using less mental effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97bf6360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. It's a city in the north-central part of the country and is known for many famous landmarks such as the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, etc. The city has been the center of French culture, politics, fashion, arts, and gastronomy. As a part of Paris, it's also famous for its lifestyle and food.\n",
      "The capital of France is Paris. It's a city in the north-central part of the country and is known for many famous landmarks such as the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, etc. The city has been the center of French culture, politics, fashion, arts, and gastronomy. As a part of Paris, it's also famous for its lifestyle and food.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model=MODEL, messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'What is the capital of France?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87600bd5",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to Rayleigh scattering, which is a phenomenon that occurs when sunlight interacts with small particles in Earth's atmosphere. \n",
      "\n",
      "Sunlight is made up of various colors, or wavelengths, and each wavelength scatters differently as it passes through the atmosphere. The shorter the wavelength (blue light) is, the more it gets scattered by the molecules and atoms in the air. When you see a blue sky, what you're actually seeing is sunlight that has been scattered in all directions by these particles, which makes it appear blue to your eyes.\n",
      "\n",
      "This is why sunrises and sunsets often appear more red or orange, as the light from the sun has to pass through more of Earth's atmosphere, causing more of the blue light to be scattered away. This scattering of shorter wavelength colors makes the sky appear more blue during the day, and less so at night when there is no direct sunlight to scatter the particles in the atmosphere."
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model=MODEL,\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8907377",
   "metadata": {},
   "source": [
    "### Vision Language Models (VLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468c26c",
   "metadata": {},
   "source": [
    "### Small Language Models\n",
    "\n",
    "Language Models come in very small sizes too. Some examples include `smollm` and `tinyllama`. While these models are more prone to hallucination, and have more limited \"intelligence,\" they can run quite fast even on less powerful hardware such as Raspberry Pis and computers with older GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bcbee",
   "metadata": {},
   "source": [
    "## Text to Image with StableDiffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053a57f",
   "metadata": {},
   "source": [
    "## Other ML Tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
